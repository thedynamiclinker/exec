#!/usr/bin/env python

import os, sys, re, glob

# Initialize this class with dirs you want to detect duplicates in.
# If you forgot some at init time, you can add arbitrarily many
# more with the self.add_directory(dir) method.

# To show the current state of the duplicate detection, use self.str
# To format the output as JSON, use self.json

class DuplicateDetector:

    def __init__(self, dirs = None, indent = "  "):

        self.dirs = sorted(set(dirs)) if dirs is not None else []
        self.indent = indent

        from collections import defaultdict
        self.hashes = defaultdict(list)

        for dir in self.dirs:
            self.add_directory(dir)

    # @S: self.hashes :: Adds hashes for dir to self.hashes
    def add_directory(self, dir):

        import hashlib

        for base, dirs, files in os.walk(dir):

            base  = os.path.realpath(base) # name of directory we're currently at

            for fn in files:
                path = os.path.join(base, fn)

                # Exclude git stuff
                if '/.git/' in path: continue

                bytes = open(path, 'rb').read()

                # Don't detect empty files as all being identical, since they might be used just for their names
                if len(bytes) == 0: continue

                md5 = hashlib.md5(bytes).hexdigest()
                self.hashes[md5].append(path)

        # This last bit isn't necessary, but it re-sorts each list of duplicates every time we add a directory
        for hash, clones in self.hashes.items():
            self.hashes[hash] = sorted(clones)

    # @G: self.hashes
    @property
    def duplicates(self):
        from collections import OrderedDict
        d = {k:v for k,v in self.hashes.items() if len(v) > 1}
        return OrderedDict(sorted(d.items()))

    # @G: self.duplicates, self.indent
    @property
    def json(self):
        indent = self.indent
        l = []
        l.append('{')
        for hash, clones in self.duplicates.items():
            l.append('{0}"{1}": ['.format(indent, hash))
            for clone in clones:
                l.append('{0}"{1}",'.format(2*indent, clone))
            l[-1] = l[-1].strip(',')
            l.append('{0}],'.format(indent))
        l[-1] = l[-1].strip(',')
        l.append('}')
        return "\n".join(l)

    # @G: self.duplicates :: Same as self.json, but uses standard library methods
    @property
    def json2(self):
        import json
        return json.dumps(self.duplicates, sort_keys = True)

    # @G: self.duplicates, self.indent
    @property
    def str(self):
        indent = self.indent
        l = []
        RELATIVE_PATH = True
        cwd = os.getcwd()
        for hash, clones in self.duplicates.items():
            l.append('{0}'.format(hash))
            for clone in clones:
                if RELATIVE_PATH:
                    clone = re.sub(f"{cwd}/", '', clone)
                l.append(indent + clone)
            l.append('')
        return "\n".join(l)

    #@G: self.str
    def show(self):
        print(self.str)

def parse_command_line():

    # Just for interactive testing purposes
    argv = sys.argv

    if (len(argv) == 1) or ('-h' in argv) or ('--help' in argv):
        print("Usage: {0} <dirs>\nPrints out duplicate files, organized by md5sum.".format(os.path.basename(argv[0])))
        sys.exit(1)

    dirs = []
    for i, arg in enumerate(argv[1:]):
        if os.path.isdir(arg):
            dirs.append(os.path.realpath(arg))
        else:
            print("Argument {0} ({1}) is not a directory.".format(i, arg))
            sys.exit(1)

    return dirs


if __name__ == '__main__':
    dirs = parse_command_line()
    dd = DuplicateDetector(dirs)

    # These still work, but the easiest way is shown below
    # print(dd.str)
    # print(dd.json)
    dd.show()
